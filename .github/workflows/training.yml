name: Model Training
on:
  schedule:
    - cron: '30 * * * *'  # Runs at :30 past every hour
  workflow_dispatch:

jobs:
  train-model:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      actions: read
      contents: read

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install xgboost scikit-learn pandas numpy joblib
        pip list
        
    # Primary download attempt
    - name: Download features (exact name)
      id: download-exact
      uses: actions/download-artifact@v4
      with:
        name: aqi-features
        path: data/
      continue-on-error: true
        
    # Secondary download attempt
    - name: Download features (pattern match)
      if: steps.download-exact.outcome == 'failure'
      id: download-pattern
      uses: actions/download-artifact@v4
      with:
        name: aqi-features-*
        path: data/
        pattern: aqi-features-*
        merge-multiple: false
        
    # Final fallback using API
    - name: Download features (API fallback)
      if: steps.download-exact.outcome == 'failure' && steps.download-pattern.outcome == 'failure'
      run: |
        import requests
        import os
        from urllib.parse import urljoin

        # Get the latest artifact ID
        api_url = f"https://api.github.com/repos/{os.environ['GITHUB_REPOSITORY']}/actions/artifacts"
        headers = {
            "Authorization": f"token {os.environ['GITHUB_TOKEN']}",
            "Accept": "application/vnd.github.v3+json"
        }
        
        response = requests.get(api_url, headers=headers)
        response.raise_for_status()
        
        artifacts = [a for a in response.json()['artifacts'] 
                    if a['name'].startswith('aqi-features')]
        
        if not artifacts:
            print("::error::No matching artifacts found")
            exit(1)
            
        latest_artifact = max(artifacts, key=lambda x: x['updated_at'])
        download_url = latest_artifact['archive_download_url']
        
        # Download and extract
        os.makedirs('data', exist_ok=True)
        response = requests.get(download_url, headers=headers, stream=True)
        response.raise_for_status()
        
        with open('data/features.zip', 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                
        os.system('unzip data/features.zip -d data/')
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      shell: python
        
    - name: Verify features
      run: |
        import pandas as pd
        import os
        
        csv_path = 'data/hourly_features.csv'
        if not os.path.exists(csv_path):
            print(f"::error::Features file not found at {csv_path}")
            print("Contents of data/ directory:")
            print(os.listdir('data'))
            exit(1)
            
        try:
            df = pd.read_csv(csv_path)
            print(f"Successfully loaded {len(df)} records")
            print("Columns:", df.columns.tolist())
        except Exception as e:
            print(f"::error::Failed to load features: {str(e)}")
            exit(1)
      shell: python
        
    - name: Train model
      run: python scripts/train_model.py
      
    - name: Upload model
      uses: actions/upload-artifact@v4
      with:
        name: aqi-model-${{ github.run_number }}
        path: models/
        retention-days: 7
